{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC4LS9oyJMgO",
        "outputId": "efa83be4-f6e9-4d86-8c6e-29846c0ea556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduction_operations.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction_operations.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <limits.h>\n",
        "\n",
        "// CUDA kernel for Sum reduction\n",
        "__global__ void sumReduction(int *input, int *output, int n) {\n",
        "    __shared__ int shared[1024];\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    // Load data to shared memory\n",
        "    shared[tid] = (idx < n) ? input[idx] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction in shared memory\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            shared[tid] += shared[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write result for this block to global memory\n",
        "    if (tid == 0) output[blockIdx.x] = shared[0];\n",
        "}\n",
        "\n",
        "// CUDA kernel for Min reduction\n",
        "__global__ void minReduction(int *input, int *output, int n) {\n",
        "    __shared__ int shared[1024];\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    shared[tid] = (idx < n) ? input[idx] : INT_MAX;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x/2; s > 0; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            if (shared[tid + s] < shared[tid])\n",
        "                shared[tid] = shared[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) output[blockIdx.x] = shared[0];\n",
        "}\n",
        "\n",
        "// CUDA kernel for Max reduction\n",
        "__global__ void maxReduction(int *input, int *output, int n) {\n",
        "    __shared__ int shared[1024];\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    shared[tid] = (idx < n) ? input[idx] : INT_MIN;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x/2; s > 0; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            if (shared[tid + s] > shared[tid])\n",
        "                shared[tid] = shared[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) output[blockIdx.x] = shared[0];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1024;\n",
        "    int h_input[N];\n",
        "    int *d_input, *d_output;\n",
        "    int h_sum, h_min, h_max;\n",
        "\n",
        "    // Initialize input data\n",
        "    for (int i = 0; i < N; i++)\n",
        "        h_input[i] = i + 1;\n",
        "\n",
        "    cudaMalloc((void**)&d_input, N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Sum Reduction\n",
        "    sumReduction<<<1, 1024>>>(d_input, d_output, N);\n",
        "    cudaMemcpy(&h_sum, d_output, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Min Reduction\n",
        "    minReduction<<<1, 1024>>>(d_input, d_output, N);\n",
        "    cudaMemcpy(&h_min, d_output, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Max Reduction\n",
        "    maxReduction<<<1, 1024>>>(d_input, d_output, N);\n",
        "    cudaMemcpy(&h_max, d_output, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Display Results\n",
        "    printf(\"Sum      : %d\\\\n\", h_sum);\n",
        "    printf(\"Average  : %.2f\\\\n\", (float)h_sum / N);\n",
        "    printf(\"Minimum  : %d\\\\n\", h_min);\n",
        "    printf(\"Maximum  : %d\\\\n\", h_max);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction_operations.cu -o reduction\n",
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e8uIaWfJeA_",
        "outputId": "161ec7a8-6bfd-44ba-b4d2-6c19f2c2a4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum      : 2189552\\nAverage  : 2138.23\\nMinimum  : 0\\nMaximum  : 1024\\n"
          ]
        }
      ]
    }
  ]
}