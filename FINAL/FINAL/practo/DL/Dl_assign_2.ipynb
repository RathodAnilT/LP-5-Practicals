{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGNNjBn-mx-9",
    "outputId": "7e3371c7-5112-45ad-8a69-43d069d6b4e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.6041 - loss: 0.6851 - val_accuracy: 0.8135 - val_loss: 0.6358\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.8293 - loss: 0.6024 - val_accuracy: 0.8414 - val_loss: 0.5079\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.8710 - loss: 0.4569 - val_accuracy: 0.8661 - val_loss: 0.3930\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.8964 - loss: 0.3407 - val_accuracy: 0.8694 - val_loss: 0.3329\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9056 - loss: 0.2724 - val_accuracy: 0.8869 - val_loss: 0.2900\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9180 - loss: 0.2301 - val_accuracy: 0.8855 - val_loss: 0.2820\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.9338 - loss: 0.1906 - val_accuracy: 0.8892 - val_loss: 0.2745\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.9445 - loss: 0.1683 - val_accuracy: 0.8893 - val_loss: 0.2716\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9546 - loss: 0.1464 - val_accuracy: 0.8900 - val_loss: 0.2691\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9616 - loss: 0.1230 - val_accuracy: 0.8848 - val_loss: 0.2816\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9683 - loss: 0.1096 - val_accuracy: 0.8845 - val_loss: 0.2974\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9748 - loss: 0.0942 - val_accuracy: 0.8795 - val_loss: 0.3040\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.2868\n",
      "\n",
      "Test Accuracy: 0.8802\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "\n",
      "Sample Prediction Result:\n",
      "Predicted Label: Negative\n",
      "Actual Label: Negative\n",
      "Review Text: ? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you ...\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# 2. Load IMDB Dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 3. Decode integer sequences into text (needed for TF-IDF)\n",
    "word_index = imdb.get_word_index()\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([index_word.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "# Decode reviews\n",
    "decoded_train = [decode_review(review) for review in train_data]\n",
    "decoded_test = [decode_review(review) for review in test_data]\n",
    "\n",
    "decoded_train[0] = \"this movie was bad\"\n",
    "\n",
    "# 4. Tokenize text to Bag-of-Words (simple word counts)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X_train_counts = vectorizer.fit_transform(decoded_train)\n",
    "X_test_counts = vectorizer.transform(decoded_test)\n",
    "\n",
    "# 5. Apply TF-IDF\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_counts).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test_counts).toarray()\n",
    "\n",
    "# 6. Build DNN Model\n",
    "# Build DNN Model with correct input dimension\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train_tfidf.shape[1],)))  # Not hardcoded\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 7. Compile Model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 8. Prepare Validation Set\n",
    "X_val = X_train_tfidf[:10000]\n",
    "partial_X_train = X_train_tfidf[10000:]\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]\n",
    "\n",
    "# 9. Train Model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    partial_X_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 10. Evaluate Model\n",
    "test_loss, test_acc = model.evaluate(X_test_tfidf, test_labels)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 11. Predict Example\n",
    "predictions = (model.predict(X_test_tfidf) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"\\nSample Prediction Result:\")\n",
    "print(\"Predicted Label:\", \"Positive\" if predictions[0] == 1 else \"Negative\")\n",
    "print(\"Actual Label:\", \"Positive\" if test_labels[0] == 1 else \"Negative\")\n",
    "print(\"Review Text:\", decoded_train[0][:300], \"...\")  # Show part of review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVrWPh4GqbWh",
    "outputId": "3d8f901b-dff9-474e-8500-d453a95819dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Text: this movie was bad ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Review Text:\", decoded_train[0][:300], \"...\")  # Show part of review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPwt2i4qCroC"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUg-EasjCx54",
    "outputId": "0703e399-6da0-446d-b700-734436158284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (25000, 500)\n",
      "Shape of X_test:  (25000, 500)\n",
      "Shape of train_labels: (25000,)\n",
      "Shape of test_labels:  (25000,)\n",
      "\n",
      "DataFrame shape: (25000, 2)\n",
      "\n",
      "DataFrame head():\n",
      "                                              review  label\n",
      "0  ? this film was just brilliant casting locatio...      1\n",
      "1  ? big hair big boobs bad music and a giant saf...      0\n",
      "2  ? this has to be one of the worst films of the...      0\n",
      "3  ? the ? ? at storytelling the traditional sort...      1\n",
      "4  ? worst mistake of my life br br i picked this...      0\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - accuracy: 0.5090 - loss: 0.6931 - val_accuracy: 0.5104 - val_loss: 0.6923\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5256 - loss: 0.6912 - val_accuracy: 0.5248 - val_loss: 0.6873\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5856 - loss: 0.6709 - val_accuracy: 0.7419 - val_loss: 0.5823\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7019 - loss: 0.5784 - val_accuracy: 0.8084 - val_loss: 0.4706\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7286 - loss: 0.5388 - val_accuracy: 0.8088 - val_loss: 0.4300\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7838 - loss: 0.4560 - val_accuracy: 0.6293 - val_loss: 0.5699\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6695 - loss: 0.5705 - val_accuracy: 0.8447 - val_loss: 0.3792\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7531 - loss: 0.4888 - val_accuracy: 0.7198 - val_loss: 0.5143\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7742 - loss: 0.4549 - val_accuracy: 0.8246 - val_loss: 0.3779\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8158 - loss: 0.4091 - val_accuracy: 0.7752 - val_loss: 0.4339\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8392 - loss: 0.3602 - val_accuracy: 0.7825 - val_loss: 0.4475\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8139 - loss: 0.3997 - val_accuracy: 0.8504 - val_loss: 0.3454\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8544 - loss: 0.3381 - val_accuracy: 0.8772 - val_loss: 0.3078\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8555 - loss: 0.3259 - val_accuracy: 0.8785 - val_loss: 0.3066\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8846 - loss: 0.2784 - val_accuracy: 0.8806 - val_loss: 0.2957\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8925 - loss: 0.2628 - val_accuracy: 0.8811 - val_loss: 0.3036\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8968 - loss: 0.2529 - val_accuracy: 0.8750 - val_loss: 0.3003\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8794 - loss: 0.2859 - val_accuracy: 0.8854 - val_loss: 0.2914\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8928 - loss: 0.2628 - val_accuracy: 0.8747 - val_loss: 0.2990\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8991 - loss: 0.2407 - val_accuracy: 0.8216 - val_loss: 0.4150\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.3040\n",
      "\n",
      "Test Accuracy: 0.8771\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "Sample Prediction Result:\n",
      "Predicted: Negative\n",
      "Actual:    Negative\n",
      "Review:    ? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you madison fans give this a miss ...\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 2. Load IMDB Dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 3. Pad Sequences (for embedding layer)\n",
    "maxlen = 500  # Maximum review length (tuneable)\n",
    "X_train = pad_sequences(train_data, maxlen=maxlen)\n",
    "X_test  = pad_sequences(test_data,  maxlen=maxlen)\n",
    "\n",
    "\n",
    "# 4. Display the shape of the padded data\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_labels: \", test_labels.shape)\n",
    "\n",
    "# 5. Prepare human-readable reviews for DataFrame inspection\n",
    "word_index = imdb.get_word_index()\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "\n",
    "def decode_review(encoded):\n",
    "    return \" \".join(index_word.get(i-3, \"?\") for i in encoded)\n",
    "\n",
    "decoded_train = [decode_review(r) for r in train_data]\n",
    "decoded_test  = [decode_review(r) for r in test_data]\n",
    "\n",
    "\n",
    "# 6. Build a DataFrame and inspect it\n",
    "train_df = pd.DataFrame({\n",
    "    \"review\": decoded_train,\n",
    "    \"label\":  train_labels\n",
    "})\n",
    "\n",
    "print(\"\\nDataFrame shape:\", train_df.shape)\n",
    "print(\"\\nDataFrame head():\")\n",
    "print(train_df.head())\n",
    "\n",
    "\n",
    "# 7. Build DNN Model with Embedding Layer\n",
    "model = models.Sequential([\n",
    "    # Embedding layer (increase the dimension)\n",
    "    layers.Embedding(input_dim=10000, output_dim=256, input_length=maxlen),  # Increase embedding dimension to 256\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "\n",
    "    # Dropout to prevent overfitting\n",
    "    layers.Dropout(0.5),  # Dropout layer added\n",
    "\n",
    "    # Fully connected layers\n",
    "    layers.Dense(128, activation=\"relu\"),  # Increased neurons\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# 8. Compile Model with Adam Optimizer\n",
    "model.compile(\n",
    "    optimizer=\"adam\",  # Changed optimizer to Adam\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 9. Prepare Validation Set\n",
    "X_val = X_train[:10000]\n",
    "partial_X_train = X_train[10000:]\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]\n",
    "\n",
    "# 10. Train Model with EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,  # Increased patience to allow more training epochs\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    partial_X_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,  # Increased number of epochs\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 11. Evaluate Model\n",
    "test_loss, test_acc = model.evaluate(X_test, test_labels)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 12. Predict Example\n",
    "preds = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(\"\\nSample Prediction Result:\")\n",
    "print(\"Predicted:\", \"Positive\" if preds[0] == 1 else \"Negative\")\n",
    "print(\"Actual:   \", \"Positive\" if test_labels[0] == 1 else \"Negative\")\n",
    "print(\"Review:   \", decode_review(test_data[0][:300]), \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5q1qQyI8iHHn",
    "outputId": "25223f9d-81d8-481d-c521-4e284250d361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "\n",
      "Custom Review Prediction:\n",
      "Review: \"This movie was absolutely fantastic and thrilling to watch\"\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "def preprocess_review(review, word_index, maxlen=500):\n",
    "    # Clean and tokenize\n",
    "    words = review.lower().split()\n",
    "    # Map words to their index (subtracting 3 because IMDB reserve indexes 0, 1, 2 for special tokens)\n",
    "    encoded = [word_index.get(word, 2) + 3 for word in words]  # 2 is \"unknown\" word\n",
    "    # Pad the sequence\n",
    "    encoded = pad_sequences([encoded], maxlen=maxlen)\n",
    "    return encoded\n",
    "\n",
    "# Example Input\n",
    "custom_review = \"This movie was absolutely fantastic and thrilling to watch\"\n",
    "\n",
    "# Preprocess it\n",
    "input_data = preprocess_review(custom_review, word_index)\n",
    "\n",
    "# Predict\n",
    "prediction = (model.predict(input_data) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Show Result\n",
    "print(\"\\nCustom Review Prediction:\")\n",
    "print(f\"Review: \\\"{custom_review}\\\"\")\n",
    "print(\"Predicted Sentiment:\", \"Positive\" if prediction[0][0] == 1 else \"Negative\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
