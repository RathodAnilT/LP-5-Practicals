{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN6av3krSN/3oshmXIjt5fZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Practical 4\n","\n","Write a CUDA Program for :\n","1. Addition of two large vectors\n","2. Matrix Multiplication using CUDA C"],"metadata":{"id":"V-z8LLKHDSfQ"}},{"cell_type":"markdown","source":["# 1. Vector Addition Using CUDA C"],"metadata":{"id":"tdlD6sGADreP"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SaT8rywCwDp","executionInfo":{"status":"ok","timestamp":1745637491900,"user_tz":-330,"elapsed":166554,"user":{"displayName":"Anil Rathod","userId":"11879838791631308534"}},"outputId":"0d207b0d-9166-4427-e9c6-3d98fbb1ee04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pycuda\n","  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytools>=2011.2 (from pycuda)\n","  Downloading pytools-2025.1.2-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n","Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.13.2)\n","Downloading pytools-2025.1.2-py3-none-any.whl (92 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pycuda\n","  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660426 sha256=c71688c68c4e08e769166c1016f51a993c880b32c6e3558f86c919eaa59e503b\n","  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n","Successfully built pycuda\n","Installing collected packages: pytools, pycuda\n","Successfully installed pycuda-2025.1 pytools-2025.1.2\n","Enter size of vectors: 5\n","Enter 5 elements of vector A: 1 2 3 4 5\n","Enter 5 elements of vector B: 10 20 30 40 50\n","\n","Addition Steps:\n","C[0] = 1 + 10 = 11\n","C[1] = 2 + 20 = 22\n","C[2] = 3 + 30 = 33\n","C[3] = 4 + 40 = 44\n","C[4] = 5 + 50 = 55\n","\n","Resultant vector C:\n","11 22 33 44 55\n"]}],"source":["# Install pycuda if not already installed\n","!pip install pycuda\n","\n","import pycuda.driver as cuda\n","import pycuda.autoinit\n","import numpy as np\n","from pycuda.compiler import SourceModule\n","\n","# Define the CUDA kernel for vector addition\n","mod = SourceModule(\"\"\"\n","__global__ void vector_add(int *A, int *B, int *C, int n)\n","{\n","    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n","    if (idx < n) {\n","        C[idx] = A[idx] + B[idx];\n","    }\n","}\n","\"\"\")\n","\n","# Function to perform vector addition\n","def vector_add_cuda(A, B):\n","    n = len(A)\n","\n","    # Allocate memory on the device\n","    A_gpu = cuda.mem_alloc(A.nbytes)\n","    B_gpu = cuda.mem_alloc(B.nbytes)\n","    C_gpu = cuda.mem_alloc(A.nbytes)  # Result vector\n","\n","    # Copy data to the device\n","    cuda.memcpy_htod(A_gpu, A)\n","    cuda.memcpy_htod(B_gpu, B)\n","\n","    # Get the CUDA function\n","    vector_add = mod.get_function(\"vector_add\")\n","\n","    # Launch the kernel (1 block of 256 threads, enough for our small array)\n","    vector_add(A_gpu, B_gpu, C_gpu, np.int32(n), block=(256, 1, 1), grid=(1, 1))\n","\n","    # Copy result from device to host\n","    C = np.empty_like(A)\n","    cuda.memcpy_dtoh(C, C_gpu)\n","\n","    return C\n","\n","# Input size and vectors\n","n = int(input(\"Enter size of vectors: \"))\n","A = np.array(list(map(int, input(f\"Enter {n} elements of vector A: \").split())), dtype=np.int32)\n","B = np.array(list(map(int, input(f\"Enter {n} elements of vector B: \").split())), dtype=np.int32)\n","\n","# Perform vector addition on GPU\n","C = vector_add_cuda(A, B)\n","\n","# Displaying addition steps\n","print(\"\\nAddition Steps:\")\n","for i in range(n):\n","    print(f\"C[{i}] = {A[i]} + {B[i]} = {C[i]}\")\n","\n","# Final Resultant Vector\n","print(\"\\nResultant vector C:\")\n","print(*C)\n"]},{"cell_type":"markdown","source":["# 2. Matrix Multiplication using CUDA (PyCUDA in Colab)"],"metadata":{"id":"3HftXu1XHCj1"}},{"cell_type":"code","source":["!pip install pycuda\n","import pycuda.driver as cuda\n","import pycuda.autoinit\n","import numpy as np\n","from pycuda.compiler import SourceModule\n","\n","# CUDA kernel for matrix multiplication\n","mod = SourceModule(\"\"\"\n","__global__ void matmul(int *A, int *B, int *C, int N)\n","{\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(row < N && col < N) {\n","        int temp = 0;\n","        for(int i = 0; i < N; i++) {\n","            temp += A[row * N + i] * B[i * N + col];\n","        }\n","        C[row * N + col] = temp;\n","    }\n","}\n","\"\"\")\n","\n","# Function to perform matrix multiplication on GPU\n","def matrix_multiply_cuda(A, B, N):\n","    # Flatten matrices to 1D arrays\n","    A_flat = A.flatten().astype(np.int32)\n","    B_flat = B.flatten().astype(np.int32)\n","    C_flat = np.zeros_like(A_flat)\n","\n","    # Allocate device memory\n","    A_gpu = cuda.mem_alloc(A_flat.nbytes)\n","    B_gpu = cuda.mem_alloc(B_flat.nbytes)\n","    C_gpu = cuda.mem_alloc(C_flat.nbytes)\n","\n","    # Copy data to device memory\n","    cuda.memcpy_htod(A_gpu, A_flat)\n","    cuda.memcpy_htod(B_gpu, B_flat)\n","\n","    # Get the CUDA function\n","    matmul = mod.get_function(\"matmul\")\n","\n","    # Define grid and block dimensions\n","    block_dim = (16, 16, 1)\n","    grid_dim = (int(np.ceil(N / block_dim[0])), int(np.ceil(N / block_dim[1])), 1)\n","\n","    # Launch the kernel (Matrix multiplication)\n","    matmul(A_gpu, B_gpu, C_gpu, np.int32(N), block=block_dim, grid=grid_dim)\n","\n","    # Copy result from device to host\n","    cuda.memcpy_dtoh(C_flat, C_gpu)\n","\n","    # Reshape result back to a 2D matrix\n","    C = C_flat.reshape((N, N))\n","    return C\n","\n","# Input size and matrices\n","N = int(input(\"Enter the size of the matrices (NxN): \"))\n","print(f\"Enter elements for matrix A ({N}x{N}):\")\n","A = np.array([list(map(int, input().split())) for _ in range(N)], dtype=np.int32)\n","\n","print(f\"Enter elements for matrix B ({N}x{N}):\")\n","B = np.array([list(map(int, input().split())) for _ in range(N)], dtype=np.int32)\n","\n","# Perform matrix multiplication on GPU\n","C = matrix_multiply_cuda(A, B, N)\n","\n","# Display matrices and result\n","print(\"\\nMatrix A:\")\n","print(A)\n","print(\"\\nMatrix B:\")\n","print(B)\n","print(\"\\nResultant Matrix C:\")\n","print(C)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiLk1qi_G8Nt","executionInfo":{"status":"ok","timestamp":1745637690652,"user_tz":-330,"elapsed":39173,"user":{"displayName":"Anil Rathod","userId":"11879838791631308534"}},"outputId":"7ecad178-130b-47a6-d284-18b535323c56"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pycuda in /usr/local/lib/python3.11/dist-packages (2025.1)\n","Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.11/dist-packages (from pycuda) (2025.1.2)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n","Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.13.2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n","  globals().clear()\n"]},{"output_type":"stream","name":"stdout","text":["Enter the size of the matrices (NxN): 2\n","Enter elements for matrix A (2x2):\n","1 2\n","3 4\n","Enter elements for matrix B (2x2):\n","5 6\n","7 8\n","\n","Matrix A:\n","[[1 2]\n"," [3 4]]\n","\n","Matrix B:\n","[[5 6]\n"," [7 8]]\n","\n","Resultant Matrix C:\n","[[19 22]\n"," [43 50]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"arPcpbc-HLLX"},"execution_count":null,"outputs":[]}]}